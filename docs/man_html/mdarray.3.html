<!-- manual page source format generated by PolyglotMan v3.2, -->
<!-- available at http://polyglotman.sourceforge.net/ -->

<html>
<head>
<title>MDARRAY(3NEMO) manual page</title>
</head>
<body bgcolor='white'>
HTML automatically generated with <A HREF=http://manpages.ubuntu.com/manpages/bionic/man1/rman.1.html>rman</A><br>
<a href='#toc'>Table of Contents</a><p>

<h2><a name='sect0' href='#toc0'>Name</a></h2>
mdarray - simple multi-dimensional (C style) array allocators with sequential
memory  
<h2><a name='sect1' href='#toc1'>Synopsis</a></h2>
<br>
<pre>#include &lt;mdarray.h&gt;
#define MDMAXDIM    8
typedef real     *mdarray1;   /* vector */typedef
mdarray1 *mdarray2;   /* matrix */typedef mdarray2 *mdarray3;   /* tensor
*/typedef mdarray3 *mdarray4;   /* hyper tensor */...
mdarray1 allocate_mdarray1(n1)mdarray2
allocate_mdarray2(n2,n1)mdarray3 allocate_mdarray3(n3,n2,n1)mdarray4 allocate_mdarray4(n4,n3,n2,n1)...void
free_mdarray1(mdarray1 x, int n1);void free_mdarray2(mdarray2 x, int n2,
int n1);void free_mdarray3(mdarray3 x, int n3, int n2, int n1);void free_mdarray4(mdarray4
x, int n4, int n3, int n2, int n1);...</pre>
<h2><a name='sect2' href='#toc2'>Description</a></h2>
<i>mdarray</i> offers a uniform
way to allocate and free multi-dimensional (real) C-style arrays. Up to MDMAXDIM
(defined via the header file)  dimensions are available. Actual data memory
is guarenteed to be sequentually in memory, as they are with static multidimensional
arrays. This makes it easy to overlay them with traditional languages such
a Fortran (with the caution of row-major and column-major differences). <p>
Arrays
are stored in row major order, if rows vary most rapidly in memory.  For
example in <br>
<pre>   double matrix a[20][10];
</pre>the right-most index (10) varies most rapidly in memory, exactly like static
C arrays, but opposite those of fortan. The matching fortran array would
be a(10,20) in this case. <p>
Example of use: ( b = A.x) <br>
<pre>    mdarray1 x = allocate_mdarray1(10);      /*  x[10]     */
    mdarray2 A = allocate_mdarray2(20,10);   /*  A[20][10] */
    mdarray1 b = allocate_mdarray1(20);      /*  b[20]     */
    int i,j;
    for (j=0; j&lt;20; j++) {
        b[j] = 0.0;
        for (i=0; i&lt;10; i++)
            b[j] += A[j][i]*x[i]
    }
    
</pre><p>
When referring to rows and columns, we write these as A[row][col] (e.g. in
C, or the current mdarray2) or  A(row,col) (e.g. in Fortran) <p>
When using this
with 3rd party software that needs to write into contiguous memory, the
address of the first element will normally be sufficient, e.g. <br>
<pre>      mdarray2 data2 = allocate_mdarray2(nrows,ncols);
      fits_read_col(fptr, TDOUBLE, data_col, 1, 1, ncols, &amp;nulval, &amp;data2[0][0],
&amp;anynul, &amp;status);      
</pre>
<h2><a name='sect3' href='#toc3'>Timing</a></h2>
The TESTBED function (<b>mdarraytest</b>) exercizes a simple initialization
of  all array elements, and summing them up. This also clearly shows how
reversing the order of array access  affects the CPU speed , viz. timings
on a P4/1600 laptop: <br>
<pre>    % time mdarraytest 4,4,4 iter=1000000  flip=f
    Working with ndim=3 MD_Array[[4][4][4]
    2.110u 0.010s 0:02.31 91.7%     0+0k 0+0io 135pf+0w
    % time mdarraytest 4,4,4 iter=1000000  flip=t
    Working with ndim=3 MD_Array[[4][4][4]
    2.050u 0.000s 0:02.14 95.7%     0+0k 0+0io 135pf+0w
    % time mdarraytest 100,100,100 iter=100 flip=f
    Working with ndim=3 MD_Array[[100][100][100]
    3.210u 0.020s 0:03.35 96.4%     0+0k 0+0io 135pf+0w
    % time mdarraytest 100,100,100 iter=100 flip=t
    Working with ndim=3 MD_Array[[100][100][100]
    30.530u 0.040s 0:31.85 95.9%    0+0k 0+0io 135pf+0w
</pre>On grus (P3/930) 5.0 vs. 19.9 sec.  On chand (P4/2500)  1.1 vs. 12.3 sec CPU. 

<h2><a name='sect4' href='#toc4'>Caveat</a></h2>
Although both static and dynamic multi-dimensional arrays  <br>
<pre>    real     s3[4][5][6];
    mdarray3 d3 = allocate_mdarray3(4,5,6);
</pre>use sequential memory, the dynamic array uses extra memory to use the 
<i>arrays of arrays</i>, and therefore the addresses <br>
<pre>    d3 !=  d3[0] != d3[0][0]
</pre>are not the same, whereas for static arrays they are <br>
<pre>    s3 ==  s3[0] == s3[0][0]
</pre>For example, for a double precision <i>a[n3][n2]n1]</i> mdarray3, instead of using
 2*n1*n2*n3 words, it will use <i>((2*n1+1)*n2+1)*n3</i> words. <p>
To quote the FFTW
manual: using it will cause FFTW to die a painful death (referring to such
dynamic arrays) 
<h2><a name='sect5' href='#toc5'>See Also</a></h2>
<br>
<pre>vectmath(3NEMO), mdbench(1NEMO)
nrutil.c (Numerical Recipes) for an alternative approach
GSL: http://www.gnu.org/software/gsl/manual/html_node/Matrices.html (cf. valarray
in C++)
http://www.fredosaurus.com/notes-cpp/arrayptr/23two-dim-array-memory-layout.html
http://www.fftw.org/
http://c-faq.com/aryptr/
</pre>
<h2><a name='sect6' href='#toc6'>Author</a></h2>
Peter Teuben 
<h2><a name='sect7' href='#toc7'>Files</a></h2>
<br>
<pre>~/src/kernel/misc<tt> </tt>&nbsp;<tt> </tt>&nbsp;mdarray.c
</pre>
<h2><a name='sect8' href='#toc8'>Update History</a></h2>
<br>
<pre>5-may-03<tt> </tt>&nbsp;<tt> </tt>&nbsp;Created   <tt> </tt>&nbsp;<tt> </tt>&nbsp;PJT
19-feb-06<tt> </tt>&nbsp;<tt> </tt>&nbsp;Allocate actually memory sequentually<tt> </tt>&nbsp;<tt> </tt>&nbsp;PJT
dec-2019<tt> </tt>&nbsp;<tt> </tt>&nbsp;Increased MDMAXDIM to 8<tt> </tt>&nbsp;<tt> </tt>&nbsp;<tt> </tt>&nbsp;<tt> </tt>&nbsp;PJT
</pre><p>

<hr><p>
<a name='toc'><b>Table of Contents</b></a><p>
<ul>
<li><a name='toc0' href='#sect0'>Name</a></li>
<li><a name='toc1' href='#sect1'>Synopsis</a></li>
<li><a name='toc2' href='#sect2'>Description</a></li>
<li><a name='toc3' href='#sect3'>Timing</a></li>
<li><a name='toc4' href='#sect4'>Caveat</a></li>
<li><a name='toc5' href='#sect5'>See Also</a></li>
<li><a name='toc6' href='#sect6'>Author</a></li>
<li><a name='toc7' href='#sect7'>Files</a></li>
<li><a name='toc8' href='#sect8'>Update History</a></li>
</ul>
</body>
</html>
